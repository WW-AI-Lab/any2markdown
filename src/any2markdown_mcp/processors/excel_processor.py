"""
Excelæ–‡æ¡£å¤„ç†å™¨

åŸºäºŽpandaså’Œopenpyxlå®žçŽ°Excelè½¬æ¢åŠŸèƒ½ï¼Œæ”¯æŒï¼š
- Excelå·¥ä½œè¡¨è½¬Markdownè¡¨æ ¼
- å¤šå·¥ä½œè¡¨å¤„ç†
- å…¬å¼è½¬æ¢
- å›¾è¡¨å¤„ç†
"""

import asyncio
import tempfile
import zipfile
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
import re

import structlog
import pandas as pd
import openpyxl
from openpyxl.chart import AreaChart, BarChart, LineChart, PieChart, ScatterChart
import io

from .base_processor import BaseProcessor

logger = structlog.get_logger(__name__)


class ExcelProcessor(BaseProcessor):
    """Excelæ–‡æ¡£å¤„ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        
        # Excelç‰¹å®šé…ç½®
        self.max_rows_per_sheet = self._get_config_value("excel_max_rows_per_sheet", 10000)
        self.include_empty_cells = self._get_config_value("excel_include_empty_cells", False)
        self.convert_formulas = self._get_config_value("excel_convert_formulas", True)
        
        logger.info("ExcelProcessor initialized")
    
    def get_supported_formats(self) -> List[str]:
        """èŽ·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
        return ["xlsx", "xls"]
    
    async def convert(self, file_content: bytes, options: Dict[str, Any]) -> Dict[str, Any]:
        """
        è½¬æ¢Excelæ–‡æ¡£
        
        Args:
            file_content: Excelæ–‡ä»¶å†…å®¹
            options: è½¬æ¢é€‰é¡¹
            
        Returns:
            è½¬æ¢ç»“æžœ
        """
        temp_files = []
        
        try:
            # éªŒè¯æ–‡ä»¶å¤§å°
            self.validate_file_size(file_content)
            
            # ä¿å­˜ä¸´æ—¶Excelæ–‡ä»¶
            temp_excel_path = await self.save_temp_file(file_content, suffix=".xlsx")
            temp_files.append(str(temp_excel_path))
            
            logger.info("Starting Excel conversion", 
                       file_size=len(file_content),
                       temp_path=str(temp_excel_path))
            
            # åˆ†æžExcelç»“æž„
            excel_info = await self._analyze_excel_structure(temp_excel_path)
            
            # æå–å›¾ç‰‡ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
            images_info = []
            if options.get("extract_images", True):
                images_info = await self._extract_images(temp_excel_path)
                # æ³¨æ„ï¼šä¸è¦å°†å›¾ç‰‡æ–‡ä»¶æ·»åŠ åˆ°temp_filesä¸­ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦è¢«ä¿ç•™ç”¨äºŽé™æ€æ–‡ä»¶æœåŠ¡
            
            # è½¬æ¢å·¥ä½œè¡¨
            markdown_content = await self._convert_worksheets(temp_excel_path, excel_info, options)
            
            # åµŒå…¥å›¾ç‰‡URLåˆ°markdownä¸­ï¼ˆå¦‚æžœæœ‰å›¾ç‰‡ï¼‰
            if images_info:
                # å¯¹äºŽExcelï¼Œéœ€è¦å¤„ç†æ¯ä¸ªå·¥ä½œè¡¨çš„å†…å®¹
                for sheet_data in markdown_content:
                    sheet_data["content"] = await self._embed_image_urls(sheet_data["content"], images_info)
            
            # åˆ†é¡µå¤„ç†ï¼ˆæŒ‰å·¥ä½œè¡¨åˆ†é¡µï¼‰
            if options.get("paginate_output", True):
                pages = await self._paginate_by_sheets(markdown_content, excel_info)
            else:
                # åˆå¹¶æ‰€æœ‰å·¥ä½œè¡¨å†…å®¹
                combined_content = "\n\n".join([sheet["content"] for sheet in markdown_content])
                pages = [{"page": 1, "content": combined_content}]
            
            # æž„å»ºå…ƒæ•°æ®
            metadata = {
                "source_type": "excel",
                "sheet_count": excel_info["sheet_count"],
                "sheet_names": excel_info["sheet_names"],
                "total_rows": excel_info["total_rows"],
                "total_columns": excel_info["total_columns"],
                "has_charts": excel_info["has_charts"],
                "images": images_info,
                "file_size": len(file_content),
                "options_used": options
            }
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = self.format_output(
                combined_content if not options.get("paginate_output", True) else pages,
                metadata,
                options.get("output_format", "markdown")
            )
            
            logger.info("Excel conversion completed successfully",
                       sheets_processed=excel_info["sheet_count"],
                       images_extracted=len(images_info))
            
            return result
            
        except Exception as e:
            logger.error("Excel conversion failed", error=str(e))
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_files:
                await self.cleanup_temp_files(temp_files)
    
    async def _analyze_excel_structure(self, excel_path: Path) -> Dict[str, Any]:
        """åˆ†æžExcelæ–‡æ¡£ç»“æž„"""
        try:
            # ä½¿ç”¨openpyxlåˆ†æžç»“æž„
            workbook = openpyxl.load_workbook(str(excel_path), read_only=True)
            
            info = {
                "sheet_count": len(workbook.sheetnames),
                "sheet_names": workbook.sheetnames,
                "total_rows": 0,
                "total_columns": 0,
                "has_charts": False,
                "has_formulas": False,
                "sheet_info": {}
            }
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                
                # èŽ·å–æœ‰æ•ˆæ•°æ®èŒƒå›´
                if sheet.max_row and sheet.max_column:
                    sheet_rows = sheet.max_row
                    sheet_cols = sheet.max_column
                else:
                    sheet_rows = 0
                    sheet_cols = 0
                
                info["total_rows"] += sheet_rows
                info["total_columns"] = max(info["total_columns"], sheet_cols)
                
                # å·¥ä½œè¡¨ä¿¡æ¯
                info["sheet_info"][sheet_name] = {
                    "rows": sheet_rows,
                    "columns": sheet_cols,
                    "has_data": sheet_rows > 0 and sheet_cols > 0
                }
            
            workbook.close()
            
            # ä½¿ç”¨pandasæ£€æŸ¥å…¬å¼å’Œå›¾è¡¨
            try:
                with pd.ExcelFile(str(excel_path)) as excel_file:
                    for sheet_name in excel_file.sheet_names:
                        # è¯»å–å°‘é‡æ•°æ®æ£€æŸ¥æ˜¯å¦æœ‰å…¬å¼
                        df = pd.read_excel(excel_file, sheet_name=sheet_name, nrows=10)
                        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„å…¬å¼æ£€æµ‹é€»è¾‘
            except Exception as e:
                logger.warning("Could not analyze Excel with pandas", error=str(e))
            
            logger.debug("Excel structure analyzed", info=info)
            return info
            
        except Exception as e:
            logger.error("Failed to analyze Excel structure", error=str(e))
            raise
    
    async def _convert_worksheets(self, excel_path: Path, excel_info: Dict[str, Any], options: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è½¬æ¢æ‰€æœ‰å·¥ä½œè¡¨"""
        worksheets_content = []
        
        try:
            # æŒ‡å®šè¦å¤„ç†çš„å·¥ä½œè¡¨
            target_sheets = options.get("sheets", excel_info["sheet_names"])
            if isinstance(target_sheets, str):
                target_sheets = [target_sheets]
            
            for sheet_name in target_sheets:
                if sheet_name not in excel_info["sheet_names"]:
                    logger.warning("Sheet not found", sheet_name=sheet_name)
                    continue
                
                logger.info("Converting sheet", sheet_name=sheet_name)
                
                try:
                    # è½¬æ¢å•ä¸ªå·¥ä½œè¡¨
                    sheet_content = await self._convert_single_sheet(excel_path, sheet_name, options)
                    
                    worksheets_content.append({
                        "sheet_name": sheet_name,
                        "content": sheet_content
                    })
                    
                except Exception as e:
                    logger.error("Failed to convert sheet", 
                               sheet_name=sheet_name, error=str(e))
                    # ç»§ç»­å¤„ç†å…¶ä»–å·¥ä½œè¡¨
                    continue
            
            return worksheets_content
            
        except Exception as e:
            logger.error("Failed to convert worksheets", error=str(e))
            raise
    
    async def _convert_single_sheet(self, excel_path: Path, sheet_name: str, options: Dict[str, Any]) -> str:
        """è½¬æ¢å•ä¸ªå·¥ä½œè¡¨"""
        try:
            # è¯»å–Excelæ•°æ®
            df = pd.read_excel(
                str(excel_path), 
                sheet_name=sheet_name,
                na_filter=not self.include_empty_cells,
                keep_default_na=not self.include_empty_cells
            )
            
            # é™åˆ¶è¡Œæ•°
            if len(df) > self.max_rows_per_sheet:
                logger.warning("Sheet has too many rows, truncating", 
                             sheet_name=sheet_name,
                             original_rows=len(df),
                             max_rows=self.max_rows_per_sheet)
                df = df.head(self.max_rows_per_sheet)
            
            # å¤„ç†ç©ºå€¼
            if not self.include_empty_cells:
                df = df.fillna("")
            
            # è½¬æ¢ä¸ºMarkdownè¡¨æ ¼
            markdown_content = await self._dataframe_to_markdown(df, sheet_name, options)
            
            return markdown_content
            
        except Exception as e:
            logger.error("Failed to convert single sheet", 
                       sheet_name=sheet_name, error=str(e))
            raise
    
    async def _dataframe_to_markdown(self, df: pd.DataFrame, sheet_name: str, options: Dict[str, Any]) -> str:
        """å°†DataFrameè½¬æ¢ä¸ºMarkdown"""
        try:
            markdown_lines = []
            
            # æ·»åŠ å·¥ä½œè¡¨æ ‡é¢˜
            markdown_lines.append(f"## {sheet_name}")
            markdown_lines.append("")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            if df.empty:
                markdown_lines.append("*This sheet is empty.*")
                return "\n".join(markdown_lines)
            
            # å¤„ç†åˆ—å
            columns = []
            for col in df.columns:
                col_name = str(col).strip()
                if col_name.startswith("Unnamed:"):
                    col_name = f"Column {col_name.split(':')[1]}"
                columns.append(col_name)
            
            # åˆ›å»ºè¡¨æ ¼å¤´éƒ¨
            markdown_lines.append("| " + " | ".join(columns) + " |")
            markdown_lines.append("| " + " | ".join(["---"] * len(columns)) + " |")
            
            # æ·»åŠ æ•°æ®è¡Œ
            for index, row in df.iterrows():
                cells = []
                for col in df.columns:
                    cell_value = row[col]
                    
                    # å¤„ç†ä¸åŒç±»åž‹çš„å€¼
                    if pd.isna(cell_value):
                        cell_str = ""
                    elif isinstance(cell_value, (int, float)):
                        if pd.isna(cell_value):
                            cell_str = ""
                        else:
                            cell_str = str(cell_value)
                    else:
                        cell_str = str(cell_value).strip()
                    
                    # è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦
                    cell_str = cell_str.replace("|", "\\|").replace("\n", " ")
                    cells.append(cell_str)
                
                markdown_lines.append("| " + " | ".join(cells) + " |")
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            markdown_lines.append("")
            markdown_lines.append(f"*Sheet contains {len(df)} rows and {len(df.columns)} columns.*")
            
            return "\n".join(markdown_lines)
            
        except Exception as e:
            logger.error("Failed to convert DataFrame to markdown", error=str(e))
            raise
    
    async def _paginate_by_sheets(self, worksheets_content: List[Dict[str, Any]], excel_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æŒ‰å·¥ä½œè¡¨åˆ†é¡µ"""
        pages = []
        
        for i, sheet_data in enumerate(worksheets_content):
            pages.append({
                "page": i + 1,
                "sheet_name": sheet_data["sheet_name"],
                "content": sheet_data["content"]
            })
        
        logger.info("Excel content paginated by sheets", total_pages=len(pages))
        return pages
    
    async def _extract_charts(self, excel_path: Path) -> List[Dict[str, Any]]:
        """æå–Excelå›¾è¡¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        charts_info = []
        
        try:
            workbook = openpyxl.load_workbook(str(excel_path))
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                
                # æ£€æŸ¥å›¾è¡¨
                if hasattr(sheet, '_charts') and sheet._charts:
                    for i, chart in enumerate(sheet._charts):
                        chart_info = {
                            "sheet": sheet_name,
                            "index": i + 1,
                            "type": type(chart).__name__,
                            "title": getattr(chart, 'title', {}).get('text', f'Chart {i+1}') if hasattr(chart, 'title') else f'Chart {i+1}'
                        }
                        charts_info.append(chart_info)
            
            workbook.close()
            
            if charts_info:
                logger.info("Charts found in Excel", count=len(charts_info))
            
            return charts_info
            
        except Exception as e:
            logger.warning("Failed to extract charts from Excel", error=str(e))
            return []
    
    def format_output(self, content: Any, metadata: Dict[str, Any], 
                     output_format: str = "markdown") -> Dict[str, Any]:
        """é‡å†™æ ¼å¼åŒ–è¾“å‡ºä»¥å¤„ç†Excelç‰¹å®šæ ¼å¼"""
        
        if output_format == "json":
            # å¯¹äºŽExcelï¼Œæä¾›æ›´ç»“æž„åŒ–çš„JSONè¾“å‡º
            if isinstance(content, list) and all(isinstance(item, dict) and "sheet_name" in item for item in content):
                # è¿™æ˜¯æŒ‰å·¥ä½œè¡¨åˆ†é¡µçš„å†…å®¹
                structured_data = {
                    "sheets": content,
                    "metadata": metadata
                }
            else:
                structured_data = {
                    "content": content,
                    "metadata": metadata
                }
            
            return {
                "success": True,
                "data": structured_data,
                "format": output_format
            }
        
        # å¯¹äºŽå…¶ä»–æ ¼å¼ï¼Œä½¿ç”¨åŸºç±»æ–¹æ³•
        return super().format_output(content, metadata, output_format)
    
    async def _extract_images(self, excel_path: Path) -> List[Dict[str, Any]]:
        """ä»ŽExcelæ–‡æ¡£ä¸­æå–å›¾ç‰‡"""
        images_info = []
        
        try:
            # Excelæ–‡æ¡£ä¹Ÿæ˜¯ä¸€ä¸ªZIPæ–‡ä»¶
            with zipfile.ZipFile(str(excel_path), 'r') as excel_zip:
                # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
                image_files = [f for f in excel_zip.namelist() 
                             if f.startswith('xl/media/') and 
                             any(f.lower().endswith(ext) for ext in 
                                 ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'])]
                
                logger.info("Found images in Excel", count=len(image_files))
                
                for img_index, img_path in enumerate(image_files):
                    try:
                        # è¯»å–å›¾ç‰‡æ•°æ®
                        img_data = excel_zip.read(img_path)
                        
                        # èŽ·å–åŽŸå§‹æ–‡ä»¶åå’Œæ‰©å±•å
                        original_filename = Path(img_path).name
                        
                        # ä¿å­˜å›¾ç‰‡ï¼ˆä½¿ç”¨å®žä¾‹IDé¿å…æ–‡ä»¶åå†²çªï¼‰
                        filename = f"excel_{self.instance_id}_img_{img_index + 1}_{original_filename}"
                        image_info = await self.save_image(img_data, filename)
                        
                        # æ·»åŠ é¢å¤–ä¿¡æ¯
                        image_info.update({
                            "index": img_index + 1,
                            "original_path": img_path,
                            "original_filename": original_filename
                        })
                        
                        images_info.append(image_info)
                        
                        logger.info("Image extracted from Excel", 
                                   index=img_index + 1,
                                   filename=filename,
                                   size=len(img_data))
                        
                    except Exception as e:
                        logger.warning("Failed to extract image from Excel", 
                                     path=img_path,
                                     error=str(e))
                        continue
            
            logger.info("Image extraction from Excel completed", count=len(images_info))
            return images_info
            
        except Exception as e:
            logger.error("Failed to extract images from Excel document", error=str(e))
            return []
    
    async def _embed_image_urls(self, content: str, images_info: List[Dict[str, Any]]) -> str:
        """åœ¨Markdownå†…å®¹ä¸­åµŒå…¥å›¾ç‰‡URL"""
        try:
            if not images_info:
                return content
            
            # åœ¨Excelå†…å®¹æœ«å°¾æ·»åŠ å›¾ç‰‡å¼•ç”¨éƒ¨åˆ†
            image_section = ["\n\n## ðŸ“· Extracted Images\n"]
            
            for i, img_info in enumerate(images_info, 1):
                filename = img_info.get("filename", f"image_{i}")
                url = img_info.get("url", "")
                size = img_info.get("size", 0)
                
                # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                if size > 1024 * 1024:
                    size_str = f"{size / (1024 * 1024):.1f} MB"
                elif size > 1024:
                    size_str = f"{size / 1024:.1f} KB"
                else:
                    size_str = f"{size} bytes"
                
                image_section.append(f"### Image {i}: {filename}")
                image_section.append(f"![{filename}]({url})")
                image_section.append(f"- **Size**: {size_str}")
                image_section.append(f"- **URL**: [{url}]({url})")
                image_section.append("")
            
            return content + "\n".join(image_section)
            
        except Exception as e:
            logger.warning("Failed to embed image URLs in Excel content", error=str(e))
            return content 