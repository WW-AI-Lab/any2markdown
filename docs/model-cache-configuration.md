# æ¨¡å‹ç¼“å­˜é…ç½®æŒ‡å—

Any2Markdown ä½¿ç”¨ marker-pdf è¿›è¡Œ PDF è½¬æ¢ï¼Œè¯¥å·¥å…·ä¾èµ–å¤šä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ä¸ºäº†æé«˜æ€§èƒ½å¹¶é¿å…é‡å¤ä¸‹è½½ï¼Œç³»ç»Ÿæ”¯æŒé…ç½®æ¨¡å‹ç¼“å­˜ç›®å½•ã€‚

## ğŸ“‹ æ¨¡å‹ç¼“å­˜æ¦‚è¿°

### ä½¿ç”¨çš„æ¨¡å‹ç±»å‹

1. **Marker-PDF æ¨¡å‹**
   - ç”¨äº PDF æ–‡æ¡£è§£æå’Œè½¬æ¢
   - åŒ…æ‹¬ OCRã€ç‰ˆé¢åˆ†æç­‰æ¨¡å‹
   - ç¼“å­˜ä½ç½®ï¼š`MODEL_CACHE_DIR`

2. **Hugging Face æ¨¡å‹**
   - Transformers æ¨¡å‹ï¼ˆæ–‡æœ¬å¤„ç†ï¼‰
   - Tokenizersï¼ˆæ–‡æœ¬åˆ†è¯ï¼‰
   - ç¼“å­˜ä½ç½®ï¼š`HF_HOME`

3. **PyTorch æ¨¡å‹**
   - é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹
   - ç¼“å­˜ä½ç½®ï¼š`TORCH_HOME`

4. **å…¶ä»–ä¾èµ–æ¨¡å‹**
   - å„ç§ NLP å’Œ CV æ¨¡å‹
   - ç¼“å­˜ä½ç½®ï¼š`TRANSFORMERS_CACHE`

## âš™ï¸ é…ç½®æ–¹æ³•

### 1. ç¯å¢ƒå˜é‡é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­è®¾ç½®ï¼š

```bash
# Marker-PDF æ¨¡å‹ç¼“å­˜
MODEL_CACHE_DIR=/path/to/models/marker

# Hugging Face æ¨¡å‹ç¼“å­˜
HF_HOME=/path/to/models/huggingface
HF_HUB_CACHE=/path/to/models/huggingface/hub
HF_ASSETS_CACHE=/path/to/models/huggingface/assets

# PyTorch æ¨¡å‹ç¼“å­˜
TORCH_HOME=/path/to/models/torch

# Transformers æ¨¡å‹ç¼“å­˜
TRANSFORMERS_CACHE=/path/to/models/transformers

# ä¸‹è½½é…ç½®
HF_HUB_ENABLE_HF_TRANSFER=false  # ä½¿ç”¨ hf_transfer åŠ é€Ÿä¸‹è½½
HF_HUB_DISABLE_PROGRESS_BARS=false  # æ˜¾ç¤ºä¸‹è½½è¿›åº¦æ¡
HF_HUB_DISABLE_TELEMETRY=true  # ç¦ç”¨é¥æµ‹æ•°æ®æ”¶é›†
```

### 2. é…ç½®æ–‡ä»¶è®¾ç½®

åœ¨ `config.toml` ä¸­é…ç½®ï¼š

```toml
[models]
# åŸºç¡€é…ç½®
cache_dir = "/path/to/models/marker"
enable_gpu = true
preload_models = true

# Hugging Face é…ç½®
hf_home = "/path/to/models/huggingface"
hf_hub_cache = "/path/to/models/huggingface/hub"
hf_assets_cache = "/path/to/models/huggingface/assets"
torch_home = "/path/to/models/torch"
transformers_cache = "/path/to/models/transformers"

# ä¸‹è½½é€‰é¡¹
hf_hub_enable_hf_transfer = false
hf_hub_disable_progress_bars = false
hf_hub_disable_telemetry = true
```

## ğŸ³ Docker éƒ¨ç½²é…ç½®

### 1. ä½¿ç”¨ Docker Composeï¼ˆæ¨èï¼‰

`docker-compose.yml` å·²é¢„é…ç½®æ¨¡å‹ç¼“å­˜æŒ‚è½½ï¼š

```yaml
services:
  any2markdown-mcp:
    volumes:
      # æ¨¡å‹ç¼“å­˜ç›®å½•æŒ‚è½½
      - ./models/marker:/home/appuser/.cache/marker
      - ./models/huggingface:/home/appuser/.cache/huggingface
      - ./models/torch:/home/appuser/.cache/torch
      - ./models/transformers:/home/appuser/.cache/transformers
```

å¯åŠ¨å‰åˆå§‹åŒ–ç›®å½•ï¼š

```bash
# åˆ›å»ºç¼“å­˜ç›®å½•ç»“æ„
./scripts/setup_model_cache.sh

# å¯åŠ¨æœåŠ¡
docker-compose up -d
```

### 2. æ‰‹åŠ¨ Docker è¿è¡Œ

```bash
# åˆ›å»ºæœ¬åœ°ç¼“å­˜ç›®å½•
mkdir -p models/{marker,huggingface,torch,transformers}

# è¿è¡Œå®¹å™¨å¹¶æŒ‚è½½ç¼“å­˜ç›®å½•
docker run -d \
  --name any2markdown \
  -p 3000:3000 \
  -v $(pwd)/models/marker:/home/appuser/.cache/marker \
  -v $(pwd)/models/huggingface:/home/appuser/.cache/huggingface \
  -v $(pwd)/models/torch:/home/appuser/.cache/torch \
  -v $(pwd)/models/transformers:/home/appuser/.cache/transformers \
  -e MODEL_CACHE_DIR=/home/appuser/.cache/marker \
  -e HF_HOME=/home/appuser/.cache/huggingface \
  any2markdown:latest
```

### 3. GPU ç¯å¢ƒé…ç½®

å¯¹äº GPU åŠ é€Ÿç¯å¢ƒï¼Œéœ€è¦é¢å¤–é…ç½®ï¼š

```bash
# ä½¿ç”¨ GPU ç‰ˆæœ¬çš„ Docker Compose
docker-compose --profile gpu up -d

# æˆ–æ‰‹åŠ¨è¿è¡Œ GPU å®¹å™¨
docker run -d \
  --name any2markdown-gpu \
  --gpus all \
  -p 3000:3000 \
  -v $(pwd)/models:/home/appuser/.cache \
  -e USE_GPU=true \
  -e CUDA_VISIBLE_DEVICES=0 \
  any2markdown:latest
```

## ğŸ“ ç›®å½•ç»“æ„

ä½¿ç”¨ `setup_model_cache.sh` è„šæœ¬ä¼šåˆ›å»ºå¦‚ä¸‹ç›®å½•ç»“æ„ï¼š

```
models/
â”œâ”€â”€ marker/                 # Marker-PDF æ¨¡å‹ç¼“å­˜
â”œâ”€â”€ huggingface/           # Hugging Face æ¨¡å‹ç¼“å­˜
â”‚   â”œâ”€â”€ hub/              # æ¨¡å‹ä»“åº“ç¼“å­˜
â”‚   â””â”€â”€ assets/           # èµ„äº§æ–‡ä»¶ç¼“å­˜
â”œâ”€â”€ torch/                # PyTorch æ¨¡å‹ç¼“å­˜
â”œâ”€â”€ transformers/         # Transformers åº“ç¼“å­˜
â””â”€â”€ README.md            # ç¼“å­˜ç›®å½•è¯´æ˜
```

## ğŸš€ é¦–æ¬¡å¯åŠ¨

### æ¨¡å‹ä¸‹è½½è¿‡ç¨‹

é¦–æ¬¡å¯åŠ¨æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¸‹è½½æ‰€éœ€æ¨¡å‹ï¼š

1. **ä¸‹è½½æ—¶é—´**ï¼šæ ¹æ®ç½‘ç»œé€Ÿåº¦ï¼Œå¯èƒ½éœ€è¦ 10-30 åˆ†é’Ÿ
2. **ä¸‹è½½å¤§å°**ï¼šçº¦ 3-5GB æ¨¡å‹æ–‡ä»¶
3. **ä¸‹è½½æ¥æº**ï¼šä¸»è¦ä» Hugging Face Hub ä¸‹è½½

### ç›‘æ§ä¸‹è½½è¿›åº¦

```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs -f any2markdown

# ç›‘æ§ç¼“å­˜ç›®å½•å¤§å°å˜åŒ–
watch -n 10 'du -sh models/*'

# æ£€æŸ¥ç½‘ç»œæ´»åŠ¨
docker stats any2markdown
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ç½‘ç»œè¿æ¥é—®é¢˜

```bash
# é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ° Hugging Face Hub
# è§£å†³ï¼šé…ç½®ä»£ç†æˆ–ä½¿ç”¨é•œåƒæº

# è®¾ç½®ä»£ç†
export HTTP_PROXY=http://proxy.company.com:8080
export HTTPS_PROXY=http://proxy.company.com:8080

# ä½¿ç”¨å›½å†…é•œåƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
export HF_ENDPOINT=https://hf-mirror.com
```

#### 2. ç£ç›˜ç©ºé—´ä¸è¶³

```bash
# æ£€æŸ¥å¯ç”¨ç©ºé—´
df -h

# æ¸…ç†æ—§çš„æ¨¡å‹ç¼“å­˜
docker system prune -a
rm -rf models/huggingface/hub/models--*/.cache
```

#### 3. æƒé™é—®é¢˜

```bash
# ä¿®å¤ç›®å½•æƒé™
sudo chown -R $USER:$USER models/
chmod -R 755 models/
```

#### 4. æ¨¡å‹åŠ è½½å¤±è´¥

```bash
# æ¸…ç†æŸåçš„ç¼“å­˜
rm -rf models/huggingface/hub/models--*/snapshots/*/
docker restart any2markdown
```

### è°ƒè¯•å‘½ä»¤

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
docker exec any2markdown env | grep -E "(HF_|TORCH_|MODEL_|TRANSFORMERS_)"

# éªŒè¯ç¼“å­˜ç›®å½•
docker exec any2markdown ls -la /home/appuser/.cache/

# æµ‹è¯•æ¨¡å‹åŠ è½½
docker exec any2markdown python -c "
import torch
from transformers import AutoTokenizer
print('PyTorch version:', torch.__version__)
print('CUDA available:', torch.cuda.is_available())
"
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ç­–ç•¥

1. **SSD å­˜å‚¨**ï¼šå°†ç¼“å­˜ç›®å½•æ”¾åœ¨ SSD ä¸Šä»¥æé«˜ I/O æ€§èƒ½
2. **é¢„åŠ è½½æ¨¡å‹**ï¼šè®¾ç½® `preload_models = true` åœ¨å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
3. **å†…å­˜ç¼“å­˜**ï¼šä¸ºæ¨¡å‹åˆ†é…è¶³å¤Ÿçš„ç³»ç»Ÿå†…å­˜

### ç½‘ç»œä¼˜åŒ–

```bash
# å¯ç”¨ hf_transfer ä»¥åŠ é€Ÿä¸‹è½½ï¼ˆéœ€è¦å®‰è£… hf_transferï¼‰
pip install hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1

# å¹¶è¡Œä¸‹è½½
export HF_HUB_ENABLE_PARALLEL_DOWNLOAD=1
```

### å®¹å™¨èµ„æºé…ç½®

```yaml
# docker-compose.yml ä¸­çš„èµ„æºé™åˆ¶
deploy:
  resources:
    limits:
      memory: 8G      # ä¸ºæ¨¡å‹åŠ è½½åˆ†é…è¶³å¤Ÿå†…å­˜
      cpus: '4.0'
    reservations:
      memory: 4G
      cpus: '2.0'
```

## ğŸ”’ å®‰å…¨è€ƒè™‘

### ç¼“å­˜ç›®å½•å®‰å…¨

```bash
# è®¾ç½®é€‚å½“çš„æ–‡ä»¶æƒé™
chmod 700 models/
chown -R appuser:appuser models/

# åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè€ƒè™‘ä½¿ç”¨åªè¯»æŒ‚è½½
docker run -v $(pwd)/models:/home/appuser/.cache:ro
```

### ç½‘ç»œå®‰å…¨

```bash
# é™åˆ¶å®¹å™¨ç½‘ç»œè®¿é—®
docker run --network=custom-network \
  --dns=8.8.8.8 \
  any2markdown:latest
```

## ğŸ“ˆ ç›‘æ§å’Œç»´æŠ¤

### ç¼“å­˜å¤§å°ç›‘æ§

```bash
#!/bin/bash
# monitor_cache.sh - ç›‘æ§ç¼“å­˜å¤§å°çš„è„šæœ¬

echo "æ¨¡å‹ç¼“å­˜ä½¿ç”¨æƒ…å†µï¼š"
echo "==================="
du -sh models/* 2>/dev/null | sort -hr

echo -e "\nç£ç›˜ç©ºé—´ä½¿ç”¨ï¼š"
echo "=================="
df -h | grep -E "(Filesystem|/dev/)"

echo -e "\nå®¹å™¨èµ„æºä½¿ç”¨ï¼š"
echo "=================="
docker stats --no-stream any2markdown 2>/dev/null || echo "å®¹å™¨æœªè¿è¡Œ"
```

### å®šæœŸæ¸…ç†

```bash
#!/bin/bash
# cleanup_cache.sh - æ¸…ç†è¿‡æœŸç¼“å­˜

# æ¸…ç† Hugging Face ä¸´æ—¶æ–‡ä»¶
find models/huggingface -name "*.tmp" -mtime +7 -delete

# æ¸…ç† PyTorch ä¸´æ—¶æ–‡ä»¶  
find models/torch -name "*.tmp" -mtime +7 -delete

# å‹ç¼©æ—¥å¿—æ–‡ä»¶
gzip logs/*.log.1 2>/dev/null

echo "ç¼“å­˜æ¸…ç†å®Œæˆ"
```

## ğŸ“š å‚è€ƒèµ„æº

- [Marker-PDF å®˜æ–¹æ–‡æ¡£](https://github.com/VikParuchuri/marker)
- [Hugging Face ç¼“å­˜æ–‡æ¡£](https://huggingface.co/docs/huggingface_hub/guides/manage-cache)
- [PyTorch æ¨¡å‹ç¼“å­˜](https://pytorch.org/docs/stable/hub.html#caching-logic)
- [Docker Volume æœ€ä½³å®è·µ](https://docs.docker.com/storage/volumes/) 